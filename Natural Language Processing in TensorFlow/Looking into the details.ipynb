{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e7983f1",
   "metadata": {},
   "source": [
    "# Looking into the details\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "24ef86aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import paskages \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import imdb\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "import io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9c1af383",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.13.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b462ce5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "426e8c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading data \n",
    "imdb , info = tfds.load(\"imdb_reviews\" , with_info=True  ,as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88fb954",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0007e7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get train and test  data \n",
    "train_data ,test_data = imdb['train'] , imdb['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d75cc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "357de7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize sentences and labels lists\n",
    "training_sentences = []\n",
    "training_labels = []\n",
    "\n",
    "testing_sentences = []\n",
    "testing_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6313e358",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'_PrefetchDataset' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9764\\726138084.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: '_PrefetchDataset' object is not subscriptable"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a45110fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over all training examples and save the sentences and labels\n",
    "for s,l in train_data:\n",
    "    training_sentences.append(s.numpy().decode(\"utf8\"))\n",
    "    training_labels.append(l.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "60f8768e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over all training examples and save the sentences and labels\n",
    "for s,l in test_data:\n",
    "    testing_sentences.append(s.numpy().decode(\"utf8\"))\n",
    "    testing_labels.append(l.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "41a85e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels lists to numpy array\n",
    "training_labels_final = np.array(training_labels)\n",
    "testing_labels_final = np.array(testing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ba89d307",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "max_length = 120\n",
    "embedding_dim = 16\n",
    "trunc_type='post'\n",
    "oov_tok = \"<OOV>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8596c27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "be9896bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=vocab_size ,oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(training_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d5981cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index= tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ece9e788",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(training_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9ccb6c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded = pad_sequences(sequences , maxlen=max_length , truncating=trunc_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "979efe59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and pad the test sequences\n",
    "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
    "testing_padded = pad_sequences(testing_sequences,maxlen=max_length, truncating=trunc_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b92fd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "max_length = 120\n",
    "embedding_dim = 16\n",
    "trunc_type='post'\n",
    "oov_tok = \"<OOV>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3ec4f04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_5 (Embedding)     (None, 120, 16)           160000    \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 1920)              0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 6)                 11526     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 7         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 171533 (670.05 KB)\n",
      "Trainable params: 171533 (670.05 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Create model Sequential\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(10000 , 16 , input_length=120  ),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(6 , activation='relu'),\n",
    "    tf.keras.layers.Dense(1 , activation='sigmoid')\n",
    "    \n",
    "])\n",
    "\n",
    "# Setup the training parameters\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a982800d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 [==============================] - 4s 4ms/step - loss: 0.4975 - accuracy: 0.7408 - val_loss: 0.3863 - val_accuracy: 0.8240\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.2372 - accuracy: 0.9096 - val_loss: 0.4125 - val_accuracy: 0.8190\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.0861 - accuracy: 0.9781 - val_loss: 0.5178 - val_accuracy: 0.8061\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.0217 - accuracy: 0.9971 - val_loss: 0.6164 - val_accuracy: 0.8037\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.0053 - accuracy: 0.9997 - val_loss: 0.7000 - val_accuracy: 0.8032\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.7461 - val_accuracy: 0.8077\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 8.5100e-04 - accuracy: 1.0000 - val_loss: 0.7941 - val_accuracy: 0.8084\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 4.7483e-04 - accuracy: 1.0000 - val_loss: 0.8391 - val_accuracy: 0.8082\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 2.6393e-04 - accuracy: 1.0000 - val_loss: 0.8858 - val_accuracy: 0.8080\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 1.6023e-04 - accuracy: 1.0000 - val_loss: 0.9273 - val_accuracy: 0.8080\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2555c381700>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(padded ,\n",
    "         training_labels_final ,\n",
    "         epochs=10 ,\n",
    "         validation_data=(testing_padded , testing_labels_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4653db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b2ceeafe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 16)\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = model.layers[0]\n",
    "\n",
    "embedding_weights = embedding_layer.get_weights()[0]\n",
    "\n",
    "print(embedding_weights.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0f0a1139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the index-word dictionary\n",
    "reverse_word_index = tokenizer.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e054ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "296a923d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open writeable files\n",
    "out_v = io.open('vecs.tsv', 'w', encoding='utf-8')\n",
    "out_m = io.open('meta.tsv', 'w', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b83be3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word_num in range(1, vocab_size):\n",
    "\n",
    "  # Get the word associated at the current index\n",
    "  word_name = reverse_word_index[word_num]\n",
    "\n",
    "  # Get the embedding weights associated with the current index\n",
    "  word_embedding = embedding_weights[word_num]\n",
    "\n",
    "  # Write the word name\n",
    "  out_m.write(word_name + \"\\n\")\n",
    "\n",
    "  # Write the word embedding\n",
    "  out_v.write('\\t'.join([str(x) for x in word_embedding]) + \"\\n\")\n",
    "\n",
    "# Close the files\n",
    "out_v.close()\n",
    "out_m.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "43796d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import files utilities in Colab\n",
    "try:\n",
    "    from google.colab import files\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "# Download the files\n",
    "else:\n",
    "    files.download('vecs.tsv')\n",
    "    files.download('meta.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58d038a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
