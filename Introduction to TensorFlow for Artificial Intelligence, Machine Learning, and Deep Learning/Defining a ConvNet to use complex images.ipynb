{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f2e1173",
   "metadata": {},
   "source": [
    "# Defining a ConvNet to use complex images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25a1ad7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import paskages\n",
    "import tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f33cb1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17628\\713201055.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m train_generator = train_datagen.flow_from_directory(\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mtrain_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mtarget_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_dir' is not defined"
     ]
    }
   ],
   "source": [
    "train_datagen =ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(300,300),\n",
    "    batch_size=128,\n",
    "    class_mode='binary'\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6250ce78",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen =ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "                                                    validation_dir,\n",
    "                                                    target_size=(300,300),\n",
    "                                            batch_size=32,\n",
    "class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798c9d82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35dc5833",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(16 ,(3,3) , activation=\"relu\",input_shape=(300,300,3)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(32 ,(3,3)),\n",
    "    tf.keras.layers.MaxPool2D(2,2) , \n",
    "    tf.keras.layers.Conv2D(64, (3,3)),\n",
    "    tf.keras.layers.MaxPool2D(2,2) ,\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512  , activation='relu'),\n",
    "    tf.keras.layers.Dense(1 ,activation='sigmoid')\n",
    "    \n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412c87a1",
   "metadata": {},
   "source": [
    "The code you provided creates a sequential model using TensorFlow Keras for a simple Convolutional Neural Network (CNN) for image classification. Let's go through each layer and its purpose:\n",
    "\n",
    "1. `tf.keras.layers.Conv2D(16, (3, 3), activation=\"relu\", input_shape=(300, 300, 3))`: The first convolutional layer with 16 filters of size 3x3. The activation function used is ReLU (Rectified Linear Unit), and the input shape is set to (300, 300, 3) which means the network expects color images of size 300x300 pixels (with three color channels: Red, Green, and Blue).\n",
    "\n",
    "2. `tf.keras.layers.MaxPooling2D(2, 2)`: A max-pooling layer with a pool size of 2x2. This layer downsamples the spatial dimensions of the previous layer by taking the maximum value within each 2x2 region.\n",
    "\n",
    "3. `tf.keras.layers.Conv2D(32, (3, 3))`: Another convolutional layer with 32 filters of size 3x3. There is no activation function specified, so it will use a linear activation by default.\n",
    "\n",
    "4. `tf.keras.layers.MaxPool2D(2, 2)`: Another max-pooling layer with a pool size of 2x2, further reducing the spatial dimensions.\n",
    "\n",
    "5. `tf.keras.layers.Conv2D(64, (3, 3))`: A third convolutional layer with 64 filters of size 3x3.\n",
    "\n",
    "6. `tf.keras.layers.MaxPool2D(2, 2)`: A third max-pooling layer with a pool size of 2x2.\n",
    "\n",
    "7. `tf.keras.layers.Flatten()`: This layer flattens the 3D output into a 1D vector, preparing it for the fully connected layers.\n",
    "\n",
    "8. `tf.keras.layers.Dense(512, activation='relu')`: A fully connected (dense) layer with 512 units and ReLU activation function.\n",
    "\n",
    "9. `tf.keras.layers.Dense(1, activation='sigmoid')`: The final fully connected layer with a single output unit and a sigmoid activation function. This layer is commonly used for binary classification tasks, where the output will be a probability between 0 and 1, representing the likelihood of the input image belonging to a particular class (e.g., 0 for one class, 1 for another).\n",
    "\n",
    "The model is constructed sequentially, where the output of one layer flows to the next layer. To use this model, you can compile it and then fit it to your training data with appropriate loss and optimization functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafdb030",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c96a6168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 298, 298, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 149, 149, 16)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 147, 147, 32)      4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 73, 73, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 71, 71, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 35, 35, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 78400)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               40141312  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,165,409\n",
      "Trainable params: 40,165,409\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3c7bfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bb562a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154f1a1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478a9a94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47be80f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
