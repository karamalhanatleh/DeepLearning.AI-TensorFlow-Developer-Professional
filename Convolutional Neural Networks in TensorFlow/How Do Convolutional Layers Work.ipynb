{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70780c22",
   "metadata": {},
   "source": [
    "# How Do Convolutional Layers Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8dc2e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40658bd9",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/convolutional-layers-for-deep-learning-neural-networks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c55f903a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import paskages \n",
    "import numpy as np\n",
    "from tensorflow.keras import Sequential\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176ff332",
   "metadata": {},
   "source": [
    "#### Example of 1D Convolutional Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0b55b8",
   "metadata": {},
   "source": [
    "We can define a one-dimensional input that has eight elements all with the value of 0.0, with a two element bump in the middle with the values 1.0.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54acf5a7",
   "metadata": {},
   "source": [
    "The input to Keras must be three dimensional for a 1D convolutional layer.\n",
    "\n",
    "The first dimension refers to each input sample; in this case, we only have one sample. The second dimension refers to the length of each sample; in this case, the length is eight. The third dimension refers to the number of channels in each sample; in this case, we only have a single channel.\n",
    "\n",
    "Therefore, the shape of the input array will be [1, 8, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80aa9703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=np.asarray([0,0,0,1,1,0,0,0])\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63f61ac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 8, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=data.reshape(1,8,1)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad211c7",
   "metadata": {},
   "source": [
    "We will define a model that expects input samples to have the shape [8, 1].\n",
    "\n",
    "The model will have a single filter with the shape of 3, or three elements wide. Keras refers to the shape of the filter as the kernel_size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c40bfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential([])\n",
    "model.add(layers.Conv1D(1,3 , input_shape=(8,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd9d52e",
   "metadata": {},
   "source": [
    "By default, the filters in a convolutional layer are initialized with random weights. In this contrived example, we will manually specify the weights for the single filter. We will define a filter that is capable of detecting bumps, that is a high input value surrounded by low input values, as we defined in our input example.\n",
    "\n",
    "The three element filter we will define looks as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f01b4f",
   "metadata": {},
   "source": [
    "The convolutional layer also has a bias input value that also requires a weight that we will set to zero.\n",
    "\n",
    "Therefore, we can force the weights of our one-dimensional convolutional layer to use our handcrafted filter as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7c8b155b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a vertical line detector\n",
    "weights= [np.asarray([[[0]] ,[[1]] ,[[0]]]) , np.asarray([0.0])]\n",
    "#store weight in model\n",
    "model.set_weights(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bae7ca2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[0]],\n",
       " \n",
       "        [[1]],\n",
       " \n",
       "        [[0]]]),\n",
       " array([0.])]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e382bf7",
   "metadata": {},
   "source": [
    "The weights must be specified in a three-dimensional structure, in terms of rows, columns, and channels. The filter has a single row, three columns, and one channel.\n",
    "\n",
    "We can retrieve the weights and confirm that they were set correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "78c07ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[[0.]],\n",
      "\n",
      "       [[1.]],\n",
      "\n",
      "       [[0.]]], dtype=float32), array([0.], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "#confirm they store \n",
    "print(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54bb46c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a6366ef",
   "metadata": {},
   "source": [
    "Finally, we can apply the single filter to our input data.\n",
    "\n",
    "We can achieve this by calling the predict() function on the model. This will return the feature map directly: that is the output of applying the filter systematically across the input sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0e629784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 278ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.]]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#apply filter to data \n",
    "yhat=model.predict(data)\n",
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89b2474",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0574c192",
   "metadata": {},
   "source": [
    "Tying all of this together, the complete example is listed below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0998e93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import asarray\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f2ab8613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[[0.]],\n",
      "\n",
      "       [[1.]],\n",
      "\n",
      "       [[0.]]], dtype=float32), array([0.], dtype=float32)]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "[[[0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]]]\n"
     ]
    }
   ],
   "source": [
    "# define input data\n",
    "data = asarray([0, 0, 0, 1, 1, 0, 0, 0])\n",
    "data = data.reshape(1, 8, 1)\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(1, 3, input_shape=(8, 1)))\n",
    "\n",
    "# define a vertical line detector\n",
    "weights = [asarray([[[0]],[[1]],[[0]]]), asarray([0.0])]\n",
    "# store the weights in the model\n",
    "model.set_weights(weights)\n",
    "# confirm they were stored\n",
    "print(model.get_weights())\n",
    "# apply filter to input data\n",
    "yhat = model.predict(data)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064c0721",
   "metadata": {},
   "source": [
    "Next, the filter is applied to the input pattern and the feature map is calculated and displayed. We can see from the values of the feature map that the bump was detected correctly.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b057e7bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9073ee38",
   "metadata": {},
   "source": [
    "Recall that the input is an eight element vector with the values: [0, 0, 0, 1, 1, 0, 0, 0].\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b05b1e",
   "metadata": {},
   "source": [
    "First, the three-element filter [0, 1, 0] was applied to the first three inputs of the input [0, 0, 0] by calculating the dot product (“.” operator), which resulted in a single output value in the feature map of zero.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3592c086",
   "metadata": {},
   "source": [
    "Recall that a dot product is the sum of the element-wise multiplications, or here it is (0 x 0) + (1 x 0) + (0 x 0) = 0. In NumPy, this can be implemented manually as:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f24fcbbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(np.asarray( [0 , 1 , 0]).dot(np.asarray([0,0,0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c664a2f6",
   "metadata": {},
   "source": [
    "In our manual example, this is as follows:\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e9c30906",
   "metadata": {},
   "source": [
    "[0, 1, 0] . [0, 0, 0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3799abe",
   "metadata": {},
   "source": [
    "The filter was then moved along one element of the input sequence and the process was repeated; specifically, the same filter was applied to the input sequence at indexes 1, 2, and 3, which also resulted in a zero output in the feature map.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cfb18729",
   "metadata": {},
   "source": [
    "[0, 1, 0] . [0, 0, 1] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b937952",
   "metadata": {},
   "source": [
    "We are being systematic, so again, the filter is moved along one more element of the input and applied to the input at indexes 2, 3, and 4. This time the output is a value of one in the feature map. We detected the feature and activated appropriately.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b0a24cb9",
   "metadata": {},
   "source": [
    "[0, 1, 0] . [0, 1, 1] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d119d6",
   "metadata": {},
   "source": [
    "The process is repeated until we calculate the entire feature map.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2afa0ea3",
   "metadata": {},
   "source": [
    "[0, 0, 1, 1, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c4f28d",
   "metadata": {},
   "source": [
    "Note that the feature map has six elements, whereas our input has eight elements. This is an artefact of how the filter was applied to the input sequence. There are other ways to apply the filter to the input sequence that changes the shape of the resulting feature map, such as padding, but we will not discuss these methods in this post.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710660b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ae967cf",
   "metadata": {},
   "source": [
    "You can imagine that with different inputs, we may detect the feature with more or less intensity, and with different weights in the filter, that we would detect different features in the input sequence.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa98117",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc090a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "08a0711b",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9eb8e2",
   "metadata": {},
   "source": [
    "### Example of 2D Convolutional Layer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f4022e",
   "metadata": {},
   "source": [
    "We can expand the bump detection example in the previous section to a vertical line detector in a two-dimensional image.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d942efc8",
   "metadata": {},
   "source": [
    "Again, we can constrain the input, in this case to a square 8×8 pixel input image with a single channel (e.g. grayscale) with a single vertical line in the middle.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1459b920",
   "metadata": {},
   "source": [
    "[0, 0, 0, 1, 1, 0, 0, 0]\n",
    "[0, 0, 0, 1, 1, 0, 0, 0]\n",
    "[0, 0, 0, 1, 1, 0, 0, 0]\n",
    "[0, 0, 0, 1, 1, 0, 0, 0]\n",
    "[0, 0, 0, 1, 1, 0, 0, 0]\n",
    "[0, 0, 0, 1, 1, 0, 0, 0]\n",
    "[0, 0, 0, 1, 1, 0, 0, 0]\n",
    "[0, 0, 0, 1, 1, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f675c80c",
   "metadata": {},
   "source": [
    "The input to a Conv2D layer must be four-dimensional.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939ad131",
   "metadata": {},
   "source": [
    "The first dimension defines the samples; in this case, there is only a single sample. The second dimension defines the number of rows; in this case, eight. The third dimension defines the number of columns, again eight in this case, and finally the number of channels, which is one in this case.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699df8f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29270a0e",
   "metadata": {},
   "source": [
    "Therefore, the input must have the four-dimensional shape [samples, rows, columns, channels] or [1, 8, 8, 1] in this case.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f383af02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input data\n",
    "data = [[0, 0, 0, 1, 1, 0, 0, 0],\n",
    " [0, 0, 0, 1, 1, 0, 0, 0],\n",
    " [0, 0, 0, 1, 1, 0, 0, 0],\n",
    " [0, 0, 0, 1, 1, 0, 0, 0],\n",
    " [0, 0, 0, 1, 1, 0, 0, 0],\n",
    " [0, 0, 0, 1, 1, 0, 0, 0],\n",
    " [0, 0, 0, 1, 1, 0, 0, 0],\n",
    " [0, 0, 0, 1, 1, 0, 0, 0]]\n",
    "\n",
    "data = np.asarray(data)\n",
    "data=data.reshape(1,8,8,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51970a1d",
   "metadata": {},
   "source": [
    "We will define the Conv2D with a single filter as we did in the previous section with the Conv1D example.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22ddb3d",
   "metadata": {},
   "source": [
    "The filter will be two-dimensional and square with the shape 3×3. The layer will expect input samples to have the shape [columns, rows, channels] or [8,8,1].\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0c572168",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create mode l\n",
    "model = Sequential()\n",
    "model.add(layers.Conv2D(1, (3,3) , input_shape=(8,8,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4145ea0a",
   "metadata": {},
   "source": [
    "We will define a vertical line detector filter to detect the single vertical line in our input data.\n",
    "\n",
    "The filter looks as follows:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "be6b3129",
   "metadata": {},
   "source": [
    "0, 1, 0\n",
    "0, 1, 0\n",
    "0, 1, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2195b1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a vertical line detector\n",
    "detector = [[[[0]],[[1]],[[0]]],\n",
    "            [[[0]],[[1]],[[0]]],\n",
    "            [[[0]],[[1]],[[0]]]]\n",
    "weights = [asarray(detector), asarray([0.0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "68da944c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[[0.]],\n",
       " \n",
       "         [[1.]],\n",
       " \n",
       "         [[0.]]],\n",
       " \n",
       " \n",
       "        [[[0.]],\n",
       " \n",
       "         [[1.]],\n",
       " \n",
       "         [[0.]]],\n",
       " \n",
       " \n",
       "        [[[0.]],\n",
       " \n",
       "         [[1.]],\n",
       " \n",
       "         [[0.]]]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#store weight in model \n",
    "model.set_weights(weights)\n",
    "#confirm\n",
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645a30e3",
   "metadata": {},
   "source": [
    "Finally, we will apply the filter to the input image, which will result in a feature map that we would expect to show the detection of the vertical line in the input image.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b1fc26d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[[0.],\n",
       "         [0.],\n",
       "         [3.],\n",
       "         [3.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [3.],\n",
       "         [3.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [3.],\n",
       "         [3.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [3.],\n",
       "         [3.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [3.],\n",
       "         [3.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [3.],\n",
       "         [3.],\n",
       "         [0.],\n",
       "         [0.]]]], dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply filter to input data\n",
    "yhat = model.predict(data)\n",
    "yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f444ad73",
   "metadata": {},
   "source": [
    "The shape of the feature map output will be four-dimensional with the shape [batch, rows, columns, filters]. We will be performing a single batch and we have a single filter (one filter and one input channel), therefore the output shape is [1, ?, ?, 1]. We can pretty-print the content of the single feature map as follows:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8e5b0ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 3.0, 3.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 3.0, 3.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 3.0, 3.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 3.0, 3.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 3.0, 3.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 3.0, 3.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "for r in range(yhat.shape[1]):\n",
    " # print each column in the row\n",
    " print([yhat[0,r,c,0] for c in range(yhat.shape[2])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e9ec5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99cf29cc",
   "metadata": {},
   "source": [
    "Tying all of this together, the complete example is listed below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b6513aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of calculation 2d convolutions\n",
    "from numpy import asarray\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "953712a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[[[0.]],\n",
      "\n",
      "        [[1.]],\n",
      "\n",
      "        [[0.]]],\n",
      "\n",
      "\n",
      "       [[[0.]],\n",
      "\n",
      "        [[1.]],\n",
      "\n",
      "        [[0.]]],\n",
      "\n",
      "\n",
      "       [[[0.]],\n",
      "\n",
      "        [[1.]],\n",
      "\n",
      "        [[0.]]]], dtype=float32), array([0.], dtype=float32)]\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "[0.0, 0.0, 3.0, 3.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 3.0, 3.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 3.0, 3.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 3.0, 3.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 3.0, 3.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 3.0, 3.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# define input data\n",
    "data = [\n",
    " [0, 0, 0, 1, 1, 0, 0, 0],\n",
    " [0, 0, 0, 1, 1, 0, 0, 0],\n",
    " [0, 0, 0, 1, 1, 0, 0, 0],\n",
    " [0, 0, 0, 1, 1, 0, 0, 0],\n",
    " [0, 0, 0, 1, 1, 0, 0, 0],\n",
    " [0, 0, 0, 1, 1, 0, 0, 0],\n",
    " [0, 0, 0, 1, 1, 0, 0, 0],\n",
    " [0, 0, 0, 1, 1, 0, 0, 0]]\n",
    "data = asarray(data)\n",
    "data = data.reshape(1, 8, 8, 1)\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(1, (3,3), input_shape=(8, 8, 1)))\n",
    "# define a vertical line detector\n",
    "detector = [[[[0]],[[1]],[[0]]],\n",
    "            [[[0]],[[1]],[[0]]],\n",
    "            [[[0]],[[1]],[[0]]]]\n",
    "weights = [asarray(detector), asarray([0.0])]\n",
    "# store the weights in the model\n",
    "model.set_weights(weights)\n",
    "# confirm they were stored\n",
    "print(model.get_weights())\n",
    "# apply filter to input data\n",
    "yhat = model.predict(data)\n",
    "for r in range(yhat.shape[1]):\n",
    " # print each column in the row\n",
    " print([yhat[0,r,c,0] for c in range(yhat.shape[2])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9f090f",
   "metadata": {},
   "source": [
    "Running the example first confirms that the handcrafted filter was correctly defined in the layer weights\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19248db",
   "metadata": {},
   "source": [
    "Next, the calculated feature map is printed. We can see from the scale of the numbers that indeed the filter has detected the single vertical line with strong activation in the middle of the feature map.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c046051e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "389d8109",
   "metadata": {},
   "source": [
    "Let’s take a closer look at what was calculated.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2202ee37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1=np.asarray([\n",
    "                [0,1,0],\n",
    "                [0,1,0],\n",
    "                [0,1,0]\n",
    "])\n",
    "\n",
    "m2=np.asarray([   \n",
    "                [0,0,0],\n",
    "                [0,0,0],\n",
    "                [0,0,0],\n",
    " ])\n",
    "\n",
    "np.tensordot(m1,m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb850b8",
   "metadata": {},
   "source": [
    "This calculation results in a single output value of 0.0, e.g., the feature was not detected. This gives us the first element in the top-left corner of the feature map.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a647554",
   "metadata": {},
   "source": [
    "Manually, this would be as follows:\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "85886219",
   "metadata": {},
   "source": [
    "0, 1, 0     0, 0, 0\n",
    "0, 1, 0  .  0, 0, 0 = 0\n",
    "0, 1, 0     0, 0, 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db6c6f6",
   "metadata": {},
   "source": [
    "The filter is moved along one column to the left and the process is repeated. Again, the feature is not detected.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "469439b1",
   "metadata": {},
   "source": [
    "0, 1, 0     0, 0, 1\n",
    "0, 1, 0  .  0, 0, 1 = 0\n",
    "0, 1, 0     0, 0, 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444d048f",
   "metadata": {},
   "source": [
    "One more move to the left to the next column and the feature is detected for the first time, resulting in a strong activation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "de74c033",
   "metadata": {},
   "source": [
    "0, 1, 0     0, 1, 1\n",
    "0, 1, 0  .  0, 1, 1 = 3\n",
    "0, 1, 0     0, 1, 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ea9ea8",
   "metadata": {},
   "source": [
    "This process is repeated until the edge of the filter rests against the edge or final column of the input image. This gives the last element in the first full row of the feature map.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "db86db62",
   "metadata": {},
   "source": [
    "[0.0, 0.0, 3.0, 3.0, 0.0, 0.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fe3ee3",
   "metadata": {},
   "source": [
    "The filter then moves down one row and back to the first column and the process is related from left to right to give the second row of the feature map. And on until the bottom of the filter rests on the bottom or last row of the input image.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f60f45",
   "metadata": {},
   "source": [
    "Again, as with the previous section, we can see that the feature map is a 6×6 matrix, smaller than the 8×8 input image because of the limitations of how the filter can be applied to the input image.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d110c5e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
